{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Agent Play Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "# from streamlit_extras.add_vertical_space import add_vertical_space\n",
    "# from utils import PERSONA, AVAILABLE_FUNCTIONS, FUNCTIONS_SPEC, Smart_Agent, add_to_cache\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path  \n",
    "import json\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] =\"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\"\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.embeddings.create(\n",
    "#                                     model=\"text-embedding-ada-002\",\n",
    "#                                     input=\"The food was delicious and the waiter...\",\n",
    "#                                     encoding_format=\"float\"\n",
    "#                                     )\n",
    "\n",
    "# embeddings = response.data[0].embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinook SQL data \n",
    "\n",
    "https://medium.com/dataherald/how-to-connect-llm-to-sql-database-with-llamaindex-fae0e54de97c\n",
    "\n",
    "https://database.guide/2-sample-databases-sqlite/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dtriepke\\Anaconda3\\envs\\smart_agent\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from llama_index import LLMPredictor, ServiceContext, SQLDatabase, VectorStoreIndex\n",
    "from llama_index.indices.struct_store import SQLTableRetrieverQueryEngine\n",
    "from llama_index.objects import SQLTableNodeMapping, ObjectIndex, SQLTableSchema\n",
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create an ObjectIndex object that allows users to use our Index data structures over arbitrary objects.  \n",
    "An Index is a data structure that allows us to quickly retrieve relevant context for a user query.   \n",
    "The arbitrary objects in our case is the table schemas in the database. \n",
    "The ObjectIndex will handle serialization to/from the object, and use an underying Index (e.g. VectorStoreIndex, ListIndex, KeywordTableIndex) as the storage mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add Table Scheme: Album\n",
      "Add Table Scheme: Artist\n",
      "Add Table Scheme: Customer\n",
      "Add Table Scheme: Employee\n",
      "Add Table Scheme: Genre\n",
      "Add Table Scheme: Invoice\n",
      "Add Table Scheme: InvoiceLine\n",
      "Add Table Scheme: Track\n",
      "Add Table Scheme: MediaType\n",
      "Add Table Scheme: Playlist\n",
      "Add Table Scheme: PlaylistTrack\n"
     ]
    }
   ],
   "source": [
    "# load all table definitions\n",
    "engine = create_engine(\"sqlite:///Chinook.db\")\n",
    "metadata_obj = MetaData()\n",
    "metadata_obj.reflect(engine)\n",
    "\n",
    "# db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "db = SQLDatabase(engine)\n",
    "table_node_mapping = SQLTableNodeMapping(db)\n",
    "\n",
    "table_schema_objs = []\n",
    "for table_name in metadata_obj.tables.keys():\n",
    "    print(\"Add Table Scheme:\", table_name)\n",
    "    table_schema_objs.append(SQLTableSchema(table_name=table_name))\n",
    "\n",
    "\n",
    "# We dump the table schema information into a vector index. The vector index is stored within the context builder for future use.\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create our query engine. A query engine is a generic interface that allows you to ask questions over your data. \n",
    "We need to connect both our database and LLM to the engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct a SQLTableRetrieverQueryEngine. \n",
    "# Note that we pass in the ObjectRetriever so that we can dynamically retrieve the table during query-time.\n",
    "# ObjectRetriever: A retriever that retrieves a set of query engine tools.\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    db,\n",
    "    obj_index.as_retriever(similarity_top_k=1),\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\n",
       "\"Description\": \"The 'Album' table in the database has three columns. The first column is 'AlbumId' which is of INTEGER type and it is the primary key of the table. The second column is 'Title' which is of NVARCHAR(160) type. The third column is 'ArtistId' which is also of INTEGER type. All three columns are not null, meaning they must contain a value.\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Describe the table album in the db and explain the context. Response in dictionary format.\")\n",
    "\n",
    "display(Markdown(f\"{response}\"))\n",
    "\n",
    "# print(response)\n",
    "# print(response.metadata['sql_query'])\n",
    "# print(response.metadata['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use this response to feed it back into the  meta object\n",
    "\n",
    "# table_schema_objs = []\n",
    "\n",
    "# import json\n",
    "# table_context =  json.loads(response.response)\n",
    "    \n",
    "# for table_name in metadata_obj.tables.keys():\n",
    "#     print(\"Add Table Schema:\", table_name, \" || with context:\", table_context[table_name] )\n",
    "#     table_schema_objs.append(SQLTableSchema(table_name=table_name, context_str = table_context[table_name]))\n",
    "\n",
    "# # We dump the table schema information into a vector index. The vector index is stored within the context builder for future use.\n",
    "# obj_index = ObjectIndex.from_objects(\n",
    "#     table_schema_objs,\n",
    "#     table_node_mapping,\n",
    "#     VectorStoreIndex,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new query engine for retreiving the top table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_engine = SQLTableRetrieverQueryEngine(\n",
    "    db,\n",
    "    obj_index.as_retriever(similarity_top_k=1),\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artist with the most tracks is Iron Maiden, with a total of 213 tracks. Iron Maiden is a British heavy metal band formed in Leyton, East London, in 1975 by bassist and primary songwriter Steve Harris. They are considered one of the most successful heavy metal bands in history, with over 100 million albums sold worldwide.\n"
     ]
    }
   ],
   "source": [
    "response = sql_query_engine.query(\"Find the artist with the most tracks and discuss the artist history.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Artist.Name, COUNT(Track.TrackId) AS TrackCount \n",
      "FROM Artist \n",
      "JOIN Album ON Artist.ArtistId = Album.ArtistId \n",
      "JOIN Track ON Album.AlbumId = Track.AlbumId \n",
      "GROUP BY Artist.ArtistId \n",
      "ORDER BY TrackCount DESC \n",
      "LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata['sql_query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Agent over several documents\n",
    "\n",
    "https://colab.research.google.com/drive/1hJEPtLCScDCZ44hLUSrfx0LDSwIhgb7s?source=post_page-----dad199e8845b--------------------------------#scrollTo=02160804-64a2-4ef3-8a0d-8c16b06fd205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] =\"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\"\n",
    "os.environ['ACTIVELOOP_TOKEN'] = 'eyJhbGciOiJIUzUxMiIsImlhdCI6MTcwMzc2Mzc2NSwiZXhwIjoxNzM1Mzg2MTE5fQ.eyJpZCI6ImRlbm5pc3RyaWVwa2UifQ.s_9d6klJ7KL6QpgDEe-XPcWo6G86Ptpp2D6TQBJC87Gt9n11JROluVFbWdwSrmjboIEGJ82Mmd2YGEwIoU99LQ'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 more sub agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the index in a local vector store form 2 different files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index not loaded\n"
     ]
    }
   ],
   "source": [
    "# Load indexes if exist:\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"/data/storage/tesla\"\n",
    "    )\n",
    "    tesla_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"/data/storage/webtext\"\n",
    "    )\n",
    "    webtext_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "    print(\"Index loaded\")\n",
    "except:\n",
    "    index_loaded = False\n",
    "    print(\"Index not loaded\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Lake Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Lake Vector Store\n",
    "from llama_index.vector_stores import DeepLakeVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_from_file_with_DeepLakeVectorStore(input_file, org_id, dataset_name):\n",
    "    \"\"\"\n",
    "    Create an index from a given file.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): Path to the input file.\n",
    "    org_id (str): Organization ID for Activeloop.\n",
    "    dataset_name (str): Name of the dataset for Activeloop.\n",
    "\n",
    "    Returns:\n",
    "    VectorStoreIndex: The created index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    documents = SimpleDirectoryReader(input_files=[input_file]).load_data()\n",
    "\n",
    "    # Set up the dataset path\n",
    "    dataset_path = f\"hub://{org_id}/{dataset_name}\"\n",
    "\n",
    "    # Create an index over the documents\n",
    "    vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=False)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    document_index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "    return document_index\n",
    "\n",
    "# Example usage\n",
    "tesla_index = create_index_from_file_with_DeepLakeVectorStore(\"./data/storage/tesla/machine_to_end_war.txt\", \"dennistriepke\", \"LlamaIndex_tesla_predictions\")\n",
    "webtext_index = create_index_from_file_with_DeepLakeVectorStore(\"./data/storage/webtext/prodigal_chapter10.txt\", \"dennistriepke\", \"LlamaIndex_tesla_prodigal_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Vectore Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # If index not exist create with simple doc reader\n",
    "# if not index_loaded:\n",
    "#     # load data\n",
    "#     tesla_docs = SimpleDirectoryReader(\n",
    "#         input_files=[\"./data/storage/tesla/machine_to_end_war.txt\"]\n",
    "#     ).load_data()\n",
    "#     webtext_docs = SimpleDirectoryReader(\n",
    "#         input_files=[\"./data/storage/webtext/prodigal_chapter10.txt\"]\n",
    "#     ).load_data()\n",
    "\n",
    "#     # build index\n",
    "#     tesla_index = VectorStoreIndex.from_documents(tesla_docs)\n",
    "#     webtext_index = VectorStoreIndex.from_documents(webtext_docs)\n",
    "\n",
    "#     # persist index\n",
    "#     tesla_index.storage_context.persist(persist_dir=\"./data/storage/tesla\")\n",
    "#     webtext_index.storage_context.persist(persist_dir=\"./data/storage/webtext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Query Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_engine = tesla_index.as_query_engine(similarity_top_k=3)\n",
    "webtext_engine = webtext_index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=tesla_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"tesla_tool\",\n",
    "            description=(\n",
    "                \"Provides information about Teslas predictions for future \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=webtext_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"webtext_tool\",\n",
    "            description=(\n",
    "                \"Provides information about tesla's life, legacy and biographical data.\"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "agent = OpenAIAgent.from_tools(query_engine_tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Added user message to memory: How was Tesla relation to behaviorists?\n",
      "=== Calling Function ===\n",
      "Calling function: webtext_tool with args: {\n",
      "\"input\": \"Tesla's relation to behaviorists\"\n",
      "}\n",
      "Got output: There is no information provided in the given context about Tesla's relation to behaviorists.\n",
      "========================\n",
      "\n",
      "Assistant: I'm sorry, but I couldn't find any information about Tesla's relation to behaviorists.\n",
      "\n",
      "Added user message to memory: \n",
      "Assistant: I apologize for the inconvenience. Unfortunately, I don't have any information about Tesla's specific relationship with behaviorists. It's possible that Tesla may have interacted with behaviorists during his lifetime, but without further information, it's difficult to provide a definitive answer.\n",
      "\n",
      "Added user message to memory: How was Teslas relation to \"Pavlov\"\n",
      "=== Calling Function ===\n",
      "Calling function: webtext_tool with args: {\n",
      "\"input\": \"Tesla's relation to Pavlov\"\n",
      "}\n",
      "Got output: There is no information provided in the context about Tesla's relation to Pavlov.\n",
      "========================\n",
      "\n",
      "Assistant: I'm sorry, but I couldn't find any information about Tesla's specific relationship with Ivan Pavlov. It's possible that they may have had some interaction or correspondence, but without further information, it's difficult to provide a definitive answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Planing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    GPTVectorStoreIndex,\n",
    ")\n",
    "from llama_index.response.pprint_utils import pprint_response\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('./data/10q/')\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    \"\"\"\n",
    "    Download a file from a given URL and save it to the specified path.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    # Download and save the file\n",
    "    urllib.request.urlretrieve(url, save_path)\n",
    "\n",
    "\n",
    "# URLs of the files to be downloaded\n",
    "urls = [\n",
    "    'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf',\n",
    "    'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf',\n",
    "    'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf'\n",
    "]\n",
    "\n",
    "# Paths where the files will be saved\n",
    "save_paths = [\n",
    "    'data/10q/uber_10q_march_2022.pdf',\n",
    "    'data/10q/uber_10q_june_2022.pdf',\n",
    "    'data/10q/uber_10q_sept_2022.pdf'\n",
    "]\n",
    "\n",
    "# Download each file\n",
    "for url, save_path in zip(urls, save_paths):\n",
    "    download_file(url, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:02<00:00, 54.00it/s] \n",
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://dennistriepke/uber_10q_march_2022', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (146, 1)      str     None   \n",
      " metadata     json      (146, 1)      str     None   \n",
      " embedding  embedding  (146, 1536)  float32   None   \n",
      "    id        text      (146, 1)      str     None   \n",
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:02<00:00, 50.83it/s] \n",
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://dennistriepke/uber_10q_june_2022', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (143, 1)      str     None   \n",
      " metadata     json      (143, 1)      str     None   \n",
      " embedding  embedding  (143, 1536)  float32   None   \n",
      "    id        text      (143, 1)      str     None   \n",
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:03<00:00, 42.77it/s] \n",
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://dennistriepke/uber_10q_sept_2022', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape      dtype  compression\n",
      "  -------    -------     -------    -------  ------- \n",
      "   text       text      (142, 1)      str     None   \n",
      " metadata     json      (142, 1)      str     None   \n",
      " embedding  embedding  (142, 1536)  float32   None   \n",
      "    id        text      (142, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "march_index = create_index_from_file_with_DeepLakeVectorStore('./data/10q/uber_10q_march_2022.pdf', \"dennistriepke\", \"uber_10q_march_2022\")\n",
    "june_index = create_index_from_file_with_DeepLakeVectorStore('./data/10q/uber_10q_june_2022.pdf', \"dennistriepke\", \"uber_10q_june_2022\")\n",
    "sept_index = create_index_from_file_with_DeepLakeVectorStore('./data/10q/uber_10q_sept_2022.pdf', \"dennistriepke\", \"uber_10q_sept_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_engine = march_index.as_query_engine(\n",
    "    similarity_top_k=3, service_context=service_context\n",
    ")\n",
    "june_engine = june_index.as_query_engine(\n",
    "    similarity_top_k=3, service_context=service_context\n",
    ")\n",
    "sept_engine = sept_index.as_query_engine(\n",
    "    similarity_top_k=3, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI Function Agent with a Query Plan Tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "query_tool_sept = QueryEngineTool.from_defaults(\n",
    "    query_engine=sept_engine,\n",
    "    name=\"sept_2022\",\n",
    "    description=(\n",
    "        f\"Provides information about Uber quarterly financials ending\"\n",
    "        f\" September 2022\"\n",
    "    ),\n",
    ")\n",
    "query_tool_june = QueryEngineTool.from_defaults(\n",
    "    query_engine=june_engine,\n",
    "    name=\"june_2022\",\n",
    "    description=(\n",
    "        f\"Provides information about Uber quarterly financials ending June\"\n",
    "        f\" 2022\"\n",
    "    ),\n",
    ")\n",
    "query_tool_march = QueryEngineTool.from_defaults(\n",
    "    query_engine=march_engine,\n",
    "    name=\"march_2022\",\n",
    "    description=(\n",
    "        f\"Provides information about Uber quarterly financials ending March\"\n",
    "        f\" 2022\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query plan tool\n",
    "from llama_index.tools import QueryPlanTool\n",
    "from llama_index import get_response_synthesizer\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    service_context=service_context\n",
    ")\n",
    "query_plan_tool = QueryPlanTool.from_defaults(\n",
    "    query_engine_tools=[query_tool_sept, query_tool_june, query_tool_march],\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(query_plan_tool.metadata.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'query_plan_tool',\n",
       "  'description': '        This is a query plan tool that takes in a list of tools and executes a query plan over these tools to answer a query. The query plan is a DAG of query nodes.\\n\\nGiven a list of tool names and the query plan schema, you can choose to generate a query plan to answer a question.\\n\\nThe tool names and descriptions are as follows:\\n\\n\\n\\n        Tool Name: sept_2022\\nTool Description: Provides information about Uber quarterly financials ending September 2022 \\n\\nTool Name: june_2022\\nTool Description: Provides information about Uber quarterly financials ending June 2022 \\n\\nTool Name: march_2022\\nTool Description: Provides information about Uber quarterly financials ending March 2022 \\n        ',\n",
       "  'parameters': {'title': 'QueryPlan',\n",
       "   'description': \"Query plan.\\n\\nContains a list of QueryNode objects (which is a recursive object).\\nOut of the list of QueryNode objects, one of them must be the root node.\\nThe root node is the one that isn't a dependency of any other node.\",\n",
       "   'type': 'object',\n",
       "   'properties': {'nodes': {'title': 'Nodes',\n",
       "     'description': 'The original question we are asking.',\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/QueryNode'}}},\n",
       "   'required': ['nodes'],\n",
       "   'definitions': {'QueryNode': {'title': 'QueryNode',\n",
       "     'description': 'Query node.\\n\\nA query node represents a query (query_str) that must be answered.\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\n(child_nodes).\\nThe tool_name and child_nodes fields are mutually exclusive.',\n",
       "     'type': 'object',\n",
       "     'properties': {'id': {'title': 'Id',\n",
       "       'description': 'ID of the query node.',\n",
       "       'type': 'integer'},\n",
       "      'query_str': {'title': 'Query Str',\n",
       "       'description': 'Question we are asking. This is the query string that will be executed. ',\n",
       "       'type': 'string'},\n",
       "      'tool_name': {'title': 'Tool Name',\n",
       "       'description': 'Name of the tool to execute the `query_str`.',\n",
       "       'type': 'string'},\n",
       "      'dependencies': {'title': 'Dependencies',\n",
       "       'description': 'List of sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if there are no sub-questions to be specified, in which case `tool_name` is specified.',\n",
       "       'type': 'array',\n",
       "       'items': {'type': 'integer'}}},\n",
       "     'required': ['id', 'query_str']}}}}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_plan_tool.metadata.to_openai_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What were the risk factors in sept 2022?\n",
      "=== Calling Function ===\n",
      "Calling function: query_plan_tool with args: {\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"query_str\": \"What were the risk factors in sept 2022?\",\n",
      "      \"tool_name\": \"sept_2022\",\n",
      "      \"dependencies\": []\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[1;3;34mExecuting node {\"id\": 1, \"query_str\": \"What were the risk factors in sept 2022?\", \"tool_name\": \"sept_2022\", \"dependencies\": []}\n",
      "\u001b[0m\u001b[1;3;38;5;200mSelected Tool: ToolMetadata(description='Provides information about Uber quarterly financials ending September 2022', name='sept_2022', fn_schema=<class 'llama_index.tools.types.DefaultToolFnSchema'>)\n",
      "\u001b[0m\u001b[1;3;34mExecuted query, got response.\n",
      "Query: What were the risk factors in sept 2022?\n",
      "Response: In September 2022, the risk factors included failure to meet regulatory requirements related to climate change or to meet stated climate change commitments, which could impact costs, operations, brand, and reputation. The ongoing COVID-19 pandemic and responses to it were also a risk, affecting demand for mobility offerings and causing driver supply constraints. Catastrophic events such as disease, weather events, war, or terrorist attacks could also adversely impact the business. Errors, bugs, or vulnerabilities in the platform's software could result in interruptions or negative experiences for users, leading to potential loss of users and revenue. The use of artificial intelligence presented additional risks, as flawed algorithms or biased data could lead to poor decisions or unintentional bias. Climate change related physical and transition risks were also a concern, including market shifts towards electric vehicles and lower carbon business models, and risks related to extreme weather events or natural disasters. Finally, the company faced risks related to emerging climate policies and the need to invest significant resources towards meeting climate commitments.\n",
      "\u001b[0mGot output: In September 2022, the risk factors included failure to meet regulatory requirements related to climate change or to meet stated climate change commitments, which could impact costs, operations, brand, and reputation. The ongoing COVID-19 pandemic and responses to it were also a risk, affecting demand for mobility offerings and causing driver supply constraints. Catastrophic events such as disease, weather events, war, or terrorist attacks could also adversely impact the business. Errors, bugs, or vulnerabilities in the platform's software could result in interruptions or negative experiences for users, leading to potential loss of users and revenue. The use of artificial intelligence presented additional risks, as flawed algorithms or biased data could lead to poor decisions or unintentional bias. Climate change related physical and transition risks were also a concern, including market shifts towards electric vehicles and lower carbon business models, and risks related to extreme weather events or natural disasters. Finally, the company faced risks related to emerging climate policies and the need to invest significant resources towards meeting climate commitments.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response=\"In September 2022, the risk factors for Uber included:\\n\\n1. Failure to meet regulatory requirements related to climate change or to meet stated climate change commitments, which could impact costs, operations, brand, and reputation.\\n2. The ongoing COVID-19 pandemic and responses to it were also a risk, affecting demand for mobility offerings and causing driver supply constraints.\\n3. Catastrophic events such as disease, weather events, war, or terrorist attacks could also adversely impact the business.\\n4. Errors, bugs, or vulnerabilities in the platform's software could result in interruptions or negative experiences for users, leading to potential loss of users and revenue.\\n5. The use of artificial intelligence presented additional risks, as flawed algorithms or biased data could lead to poor decisions or unintentional bias.\\n6. Climate change related physical and transition risks were also a concern, including market shifts towards electric vehicles and lower carbon business models, and risks related to extreme weather events or natural disasters.\\n7. Finally, the company faced risks related to emerging climate policies and the need to invest significant resources towards meeting climate commitments.\", source_nodes=[NodeWithScore(node=TextNode(id_='b45c7bfb-8ffe-442a-b9ae-8f02ab6b8b3e', embedding=None, metadata={'page_label': '74', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3a5c093c-3538-4e9a-8507-e2bbc7076143', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '74', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, hash='d9a5e67c192432ec500b4b2c3a56ddc48599e9e712b3fa9179290454aa545d6f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='417ca17c-a3a3-4a8d-afd8-600fb0bcd01c', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '74', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, hash='7d99bf421441bea453804ba46cba118136906d9bf973e0f86247f2a44b57715f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b794f10b-b341-414b-8c89-d8f51517397e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='a54de58dc6351427d2fb5d916f39c746098633d3809e24fbf84ce1ca1f01d4ab')}, hash='b3068da5ed3908d794c9076930672431e0fe14d561b7dc4abba2c3af7efcc0c1', text='Any failure to\\nmeet regulatory requirements related to climate change, or to meet our stated climate change commitments on the timeframe we committed to, or at all, could have\\nan adverse impact on our costs and ability to operate, as well as harm our brand, reputation, and consequently, our business.\\nGeneral Economic Risks\\nOutbreaks of contagious disease, such as the COVID-19 pandemic and the impact of actions to mitigate the such disease or pandemic, have adversely impacted\\nand could continue to adversely impact our business, financial condition and results of operations.\\nOccurrence of a catastrophic event, including but not limited to disease, a weather event, war, or terrorist attack, could adversely impact our business, financial\\ncondition and results of operation. We also face risks related to health epidemics, outbreaks of contagious disease, and other adverse health developments. For\\nexample, the ongoing COVID-19 pandemic and responses to it have had, and may continue to have, an adverse impact on our business and operations, including,\\nfor example, by reducing the demand for our Mobility offerings globally, and affecting travel behavior and demand. Even as COVID-related restrictions have been\\nlifted and many regions around the world are making progress in their recovery from the pandemic, we have experienced and may continue to experience Driver\\nsupply constraints, and we are observing that consumer demand for Mobility is recovering faster than driver availability, as such supply constraints have been and\\nmay continue to be impacted by concerns regarding the COVID-19 pandemic. Furthermore, to support social distancing, we temporarily suspended our shared\\nrides offering globally, and recently re-launched our shared rides offering in certain regions.\\n73', start_char_idx=4469, end_char_idx=6258, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8050868511199951), NodeWithScore(node=TextNode(id_='417ca17c-a3a3-4a8d-afd8-600fb0bcd01c', embedding=None, metadata={'page_label': '74', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3a5c093c-3538-4e9a-8507-e2bbc7076143', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '74', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, hash='d9a5e67c192432ec500b4b2c3a56ddc48599e9e712b3fa9179290454aa545d6f'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='09153447-71ea-4fa3-9923-6d942256cbe3', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '73', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, hash='3e8174880129a8f70b97aed94585a6f877fe5df099582ff533e60649c334d54f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b45c7bfb-8ffe-442a-b9ae-8f02ab6b8b3e', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4862564636269739d75565c6c9dc166659cf52e29ec337fe9b85802beeb2ce7d')}, hash='8e62657765be470bd76567c6f131edd70c79734e53d9c893be250bbc587719b8', text='platform to platform users. In addition, our release of new software in the past has inadvertently caused, and may in the future cause, interruptions in the\\navailability or functionality of our platform. Any errors, bugs, or vulnerabilities discovered in our code or systems after release could result in an interruption in the\\navailability of our platform or a negative experience for Drivers, consumers, merchants, Shippers, and Carriers, and could also result in negative publicity and\\nunfavorable media coverage, damage to our reputation, loss of platform users, loss of revenue or liability for damages, regulatory inquiries, or other proceedings,\\nany of which could adversely affect our business and financial results. In addition, our growing use of artificial intelligence (“AI”) (including machine learning) in\\nour offerings presents additional risks. AI algorithms or automated processing of data may be flawed and datasets may be insufficient or contain biased information.\\nInappropriate or controversial data practices by us or others could impair the acceptance of AI solutions or subject us to lawsuits and regulatory investigations.\\nThese deficiencies could undermine the decisions, predictions or analysis AI applications produce, or lead to unintentional bias and discrimination, subjecting us to\\ncompetitive harm, legal liability, and brand or reputational harm.\\nWe are subject to climate change risks, including physical and transitional risks, and if we are unable to manage such risks, our business may be adversely\\nimpacted.\\nWe face climate change related physical and transition risks, which include the risk of market shifts toward electric vehicles (“EVs”) and lower carbon\\nbusiness models and risks related to extreme weather events or natural disasters. Climate-related events, including the increasing frequency, severity and duration\\nof extreme weather events and their impact on critical infrastructure in the United States and elsewhere, have the potential to disrupt our business, our third-party\\nsuppliers, and the business of merchants, Shippers, Carriers and Drivers using our platform, and may cause us to experience higher losses and additional costs to\\nmaintain or resume operations. Additionally, we are subject to emerging climate policies such as a regulation adopted in California in May 2021 requiring 90% of\\nvehicle miles traveled by rideshare fleets in California to have been in zero emission vehicles by 2030, with interim targets beginning in 2023. In addition, Drivers\\nmay be subject to climate-related policies that indirectly impact our business, such as the Congestion Charge Zone and Ultra Low Emission Zone schemes adopted\\nin London that impose fees on drivers in fossil-fueled vehicles, which may impact our ability to attract and maintain Drivers on our platform, and to the extent we\\nexperience Driver supply constraints in a given market, we may need to increase Driver incentives.\\nWe have made climate related commitments that require us to invest significant effort, resources, and management time and circumstances may arise,\\nincluding those beyond our control, that may require us to revise the contemplated timeframes for implementing these commitments.\\nWe have made climate related commitments, including our commitment to 100% renewable electricity for our U.S. offices by 2025, our commitment to net\\nzero climate emissions from corporate operations by 2030, and our commitment to be a net zero company by 2040. In addition, our Supplier Code of Conduct sets\\nenvironmental standards for our supply chain, and we recognize that there are inherent climate-related risks wherever business is conducted. Progressing towards\\nour climate commitments requires us to invest significant effort, resources, and management time, and circumstances may arise, including those beyond our\\ncontrol, that may require us to revise our timelines and/or climate commitments. For example, the COVID-19 pandemic has negatively impacted our ability to\\ndedicate resources to make the progress on our climate commitments that we initially anticipated. In addition, our ability to meet our climate commitments is\\ndependent on external factors such as rapidly changing regulations, policies and related interpretation, advances in technology such as battery storage, as well the\\navailability, cost and accessibility of EVs to Drivers, and the availability of EV charging infrastructure that can be efficiently accessed by Drivers. Any failure to\\nmeet regulatory requirements related to climate change, or to meet our stated climate change commitments on the timeframe we committed to, or at all, could have\\nan adverse impact on our costs and ability to operate, as well as harm our brand, reputation, and consequently, our business.\\nGeneral Economic Risks\\nOutbreaks of contagious disease, such as the COVID-19 pandemic and the impact of actions to mitigate the such disease or pandemic, have adversely impacted\\nand could continue to adversely impact our business, financial condition and results of operations.\\nOccurrence of a catastrophic event, including but not limited to disease, a weather event, war, or terrorist attack, could adversely impact our business, financial\\ncondition and results of operation.', start_char_idx=0, end_char_idx=5248, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7971985340118408), NodeWithScore(node=TextNode(id_='ccedf78e-e18c-4050-b9df-14ef2e9aa375', embedding=None, metadata={'page_label': '13', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='782c6d0a-8d5b-46bb-9687-0f6af92dac83', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '13', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, hash='65a361b31c8955c7aa285c6c4eafc3b6ba7ff80d6fa65d47d076f0aa5b7a676e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='aec16133-44ec-4345-bbf6-0970f858dfb9', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '13', 'file_name': 'uber_10q_sept_2022.pdf', 'file_path': 'data\\\\10q\\\\uber_10q_sept_2022.pdf', 'file_type': 'application/pdf', 'file_size': 1178622, 'creation_date': '2023-12-28', 'last_modified_date': '2023-12-28', 'last_accessed_date': '2023-12-28'}, hash='b7bc24558d36070e4c5b5a2aa70a0620f68f0d9d11e9e49d7f011910ce2d02ef'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c3a71964-338d-41f0-8e04-f86e94b0796d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='801262d0c28cde0ec3c5eadf0c5c1fb9f98a37ebbeb212cb66286cc2d70513cb')}, hash='f8bc6ad628a8a31d744ccbd8ba7df91e5d6b920e704ae3b0731c97a66e0eae82', text='Estimates are based on historical experience, where\\napplicable, and other assumptions which management believes are reasonable under the circumstances. Additionally, we considered the impacts of the coronavirus\\npandemic (“COVID-19”) on the assumptions and inputs (including market data) supporting certain of these estimates, assumptions and judgments. On an ongoing\\nbasis, management evaluates estimates, including, but not limited to: fair values of investments and other financial instruments (including the measurement of\\ncredit or impairment losses); useful lives of amortizable long-lived assets; fair value of acquired intangible assets and related impairment assessments; impairment\\nof goodwill; stock-based compensation; income taxes and non-income tax reserves; certain deferred tax assets and tax liabilities; insurance reserves; and other\\ncontingent liabilities. These estimates are inherently subject to judgment and actual results could differ from those estimates.\\nCertain Significant Risks and Uncertainties - COVID-19\\nCOVID-19 restrictions have had an adverse impact on our business and operations by reducing, in particular, the global demand for Mobility offerings. It is\\nnot possible to predict COVID-19’s cumulative and ultimate impact on our future business operations, results of operations, financial position, liquidity, and cash\\nflows. The extent of the impact of COVID-19 on our business and financial results will depend largely on future developments, including: outbreaks or variants of\\nthe virus, both globally and within the United\\n12', start_char_idx=4007, end_char_idx=5573, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7916276454925537)], metadata=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [query_plan_tool],\n",
    "    max_function_calls=10,\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent.query(\"What were the risk factors in sept 2022?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Query DAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'QueryNode',\n",
       " 'description': 'Query node.\\n\\nA query node represents a query (query_str) that must be answered.\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\n(child_nodes).\\nThe tool_name and child_nodes fields are mutually exclusive.',\n",
       " 'type': 'object',\n",
       " 'properties': {'id': {'title': 'Id',\n",
       "   'description': 'ID of the query node.',\n",
       "   'type': 'integer'},\n",
       "  'query_str': {'title': 'Query Str',\n",
       "   'description': 'Question we are asking. This is the query string that will be executed. ',\n",
       "   'type': 'string'},\n",
       "  'tool_name': {'title': 'Tool Name',\n",
       "   'description': 'Name of the tool to execute the `query_str`.',\n",
       "   'type': 'string'},\n",
       "  'dependencies': {'title': 'Dependencies',\n",
       "   'description': 'List of sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if there are no sub-questions to be specified, in which case `tool_name` is specified.',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'integer'}}},\n",
       " 'required': ['id', 'query_str']}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.tools.query_plan import QueryPlan, QueryNode\n",
    "\n",
    "\n",
    "QueryPlan.schema()[\"definitions\"][\"QueryNode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query_plan = QueryPlan(\n",
    "#     nodes=[\n",
    "#         QueryNode(\n",
    "#             id=1,\n",
    "#             query_str=\"risk factors\",\n",
    "#             tool_name=\"sept_2022\",\n",
    "#             dependencies=[],\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Planner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with an agent that sources: \n",
    "\n",
    "1. SQL\n",
    "2. PDF Reports  \n",
    "3. Google Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "\n",
    "query_engine_tools_pool = []\n",
    "query_engine_tools_pool = query_engine_tools_pool + query_engine_tools + [query_plan_tool] #+ [sql_query_engine] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAgent.from_tools(\n",
    "    query_engine_tools_pool,\n",
    "    max_function_calls=10,\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\n",
    "    verbose=True,\n",
    "    system_prompt=\"You are an assistant that will answer question based on 4 tools. Every queston you receive, you will plan the query and decide which tool to use.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What were the risk factors in sept 2022?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='The query plan for this question would be:\\n\\n1. Use the `sept_2022` tool to get information about Uber\\'s financials for September 2022.\\n\\nHere is how we can use the `query_plan_tool` to answer this question:\\n\\n```typescript\\n{\\n  \"nodes\": [\\n    {\\n      \"id\": 1,\\n      \"query_str\": \"What were the risk factors in sept 2022?\",\\n      \"tool_name\": \"sept_2022\",\\n      \"dependencies\": []\\n    }\\n  ]\\n}\\n```\\n\\nWe will use the `query_plan_tool` to execute this plan.', source_nodes=[], metadata=None)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query(\"What were the risk factors in sept 2022?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
